@book{PCA,
   title =     {Principal Component Analysis},
   author =    {I.T. Jolliffe},
   publisher = {Springer},
   isbn =      {9781441929990,1441929991},
   year =      {2010},
   series =    {Springer Series in Statistics},
   edition =   {2nd ed.}
}
@article{Jolliffe2016,
abstract = {Large datasets are increasingly common and are often difficult to interpret. Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance. Finding such new variables, the principal components, reduces to solving an eigenvalue/eigenvector problem, and the new variables are defined by the dataset at hand, not a priori, hence making PCA an adaptive data analysis technique. It is adaptive in another sense too, since variants of the technique have been developed that are tailored to various different data types and structures. This article will begin by introducing the basic ideas of PCA, discussing what it can and cannot do. It will then describe some variants of PCA and their application.},
author = {Jolliffe, Ian T. and Cadima, Jorge},
doi = {10.1098/rsta.2015.0202},
file = {:C$\backslash$:/Users/Gerard/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jolliffe, Cadima - 2016 - Principal component analysis a review and recent developments.pdf:pdf},
issn = {1364-503X},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
keywords = {Dimension reduction,Eigenvectors,Multivariate analysis,Palaeontology},
month = {apr},
number = {2065},
pages = {20150202},
publisher = {Royal Society of London},
title = {{Principal component analysis: a review and recent developments}},
url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202},
volume = {374},
year = {2016}
}
@article{wold1987principal,
  title={Principal component analysis},
  author={Wold, Svante and Esbensen, Kim and Geladi, Paul},
  journal={Chemometrics and intelligent laboratory systems},
  volume={2},
  number={1-3},
  pages={37--52},
  year={1987},
  publisher={Elsevier}
}
@article{abdi2010principal,
  title={Principal component analysis},
  author={Abdi, Herv{\'e} and Williams, Lynne J},
  journal={Wiley interdisciplinary reviews: computational statistics},
  volume={2},
  number={4},
  pages={433--459},
  year={2010},
  publisher={Wiley Online Library}
}

@article{blocksvd,
   title={A Distributed and Incremental SVD Algorithm for Agglomerative Data Analysis on Large Networks},
   volume={37},
   ISSN={1095-7162},
   url={http://dx.doi.org/10.1137/16M1058467},
   DOI={10.1137/16m1058467},
   number={4},
   journal={SIAM Journal on Matrix Analysis and Applications},
   publisher={Society for Industrial & Applied Mathematics (SIAM)},
   author={Iwen, M. A. and Ong, B. W.},
   year={2016},
   month={Jan},
   pages={1699â€“1718}
}

@article{kmeans,
   title={Pthread Parallel K-means},
   url={http://barbara.stattenfield.org/papers/cs267paper.pdf},
   publisher={UC Berkele},
   author={Barbara Hohlt},
   year={2001},
   month={Dec}
}
@inproceedings{liang2010design,
  title={Design and evaluation of a parallel k-nearest neighbor algorithm on CUDA-enabled GPU},
  author={Liang, Shenshen and Liu, Ying and Wang, Cheng and Jian, Liheng},
  booktitle={2010 IEEE 2nd Symposium on Web Society},
  pages={53--60},
  year={2010},
  organization={IEEE}
}
